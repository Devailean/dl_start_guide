{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepNeuralNetwork.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOxSnfhJNpU5QKdX/dxlnBO"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"IHr5KOuvXSpx","colab_type":"code","outputId":"1740e9ac-db8c-4ef1-eefe-5f83695cd554","executionInfo":{"status":"ok","timestamp":1588074465082,"user_tz":-540,"elapsed":2547,"user":{"displayName":"JeiKei Lim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBVS8KGCKLy88ikhL2CqJZ1J5awuet90XI1Sgg55E=s64","userId":"06532207265815493900"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tqdm import tqdm\n","\n","sns.set()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FiSkYyw1XUcl","colab_type":"code","colab":{}},"source":["class Activation:\n","  def __init__(self):\n","    pass\n","  \n","  def relu(x):\n","    # return np.max(0, x)\n","    return np.vectorize(lambda x_: max(0, x_))(x)\n","  \n","  def softmax(x):\n","    s = np.exp(x - np.expand_dims(x.max(axis=1), axis=1))\n","    \n","    return s / np.expand_dims(s.sum(axis=1), axis=1)\n","  \n","  def sigmoid(x):\n","    return 1 / (1+np.exp(-x))\n","\n","class Derivative:\n","  def __init(self):\n","    pass\n","\n","  def relu(x):\n","    return np.vectorize(lambda x_: 0 if x_ < 0 else 1)(x)\n","    # return 0 if x < 0 else 1\n","\n","  def softmax(x):\n","    # s = x.reshape(-1, 1)\n","    # return np.diagflat(s) - np.dot(s, s.T)\n","    return Derivative.sigmoid(x)\n","\n","  def sigmoid(x):\n","    return x*(1-x)\n","\n","\n","class Neuron:\n","  def __init__(self, n_input, n_output, activation='sigmoid'):\n","    self.w = np.random.randn(n_input+1, n_output) * np.sqrt(2/(n_input+n_output))\n","\n","    if activation == 'relu':\n","      self.activation = Activation.relu\n","      self.derivative = Derivative.relu\n","    elif activation == 'softmax':\n","      self.activation = Activation.softmax\n","      self.derivative = Derivative.softmax\n","    else:\n","      self.activation = Activation.sigmoid\n","      self.derivative = Derivative.sigmoid\n","  \n","  def forward(self, x, append_bias=True):\n","    if append_bias:\n","      x = Neuron.append_bias(x)\n","    h = self.activation(np.matmul(x, self.w))\n","\n","    return h\n","\n","  def backward(self, x, y, append_bias=True):\n","    if append_bias:\n","      x = Neuron.append_bias(x)\n","    h = self.activation(np.matmul(x, self.w))\n","    delta_out = (y-h) * self.derivative(h)\n","    \n","    wn = np.matmul(x.T, delta_out)\n","\n","    return wn, delta_out, h\n","\n","  def train(self, x, y, learning_rate=0.01, append_bias=True):\n","    wn, h = self.backward(x, y, append_bias=append_bias)\n","    \n","    loss = np.sum(np.abs(h-y))\n","\n","    self.w = self.w + wn * learning_rate\n","\n","    return loss\n","\n","  def append_bias(x):\n","    return np.concatenate([np.ones((x.shape[0], 1)), x], axis=1)\n","\n","\n","class ANN:\n","  def __init__(self, layer=[(), 'relu']):\n","    self.layers = []\n","    for l in layer:\n","      self.layers.append(Neuron(l[0][0], l[0][1], activation=l[1]))\n","\n","  def forward(self, x):\n","    h = self.layers[0].forward(x)\n","\n","    for i in range(1, len(self.layers)):\n","      h = self.layers[i].forward(h, append_bias=False)\n","    \n","    return h\n","\n","  def train(self, x, y, learning_rate=0.01):\n","    xn = Neuron.append_bias(x)\n","\n","    hs = []\n","    hs.append(self.layers[0].forward(xn, append_bias=False))\n","    for i in range(1, len(self.layers)):\n","      hs.append(self.layers[i].forward(hs[-1], append_bias=False))\n","    \n","    ws = []\n","    d_outs = []\n","    wn, d_out, h = self.layers[-1].backward(hs[-2], y, append_bias=False)\n","    ws.append(wn)\n","    d_outs.append(d_out)\n","    \n","    for i in range(len(self.layers)-2, 0, -1):\n","      d_out = np.matmul(d_outs[0], self.layers[i+1].w.T) * self.layers[i].derivative(hs[i])\n","      wn = np.matmul(hs[i-1].T, d_out)\n","\n","      d_outs.insert(0, d_out)\n","      ws.insert(0, wn)\n","    \n","    d_out = np.matmul(d_outs[0], self.layers[1].w.T) * self.layers[0].derivative(hs[0])\n","    wn = np.matmul(xn.T, d_out)\n","\n","    ws.insert(0, wn)\n","    d_outs.insert(0, d_out)\n","\n","    for i in range(len(self.layers)):\n","      self.layers[i].w += ws[i] * learning_rate\n","\n","    loss = np.sum(np.abs(y-hs[-1]))\n","\n","    return loss\n","  \n","  def fit(self, x, y, learning_rate=0.01, epoch=1000, batch_size=1000):\n","    for i in range(epoch):\n","      loss = 0\n","      total_batch = x.shape[0] // batch_size\n","      with tqdm(total=total_batch) as pbar:\n","        for j in range(total_batch):\n","          s_idx = j*batch_size\n","          e_idx = (j+1)*batch_size\n","          x_batch = x[s_idx:e_idx]\n","          y_batch = y[s_idx:e_idx]\n","          loss += self.train(x_batch, y_batch, learning_rate=learning_rate)\n","\n","          pbar.set_description(\"Epoch : {:02d}/{:02d} , Loss : {:.3f}\".format(i+1, epoch, loss/(j+1)))\n","          pbar.update()\n","      loss /= total_batch\n","\n","    return loss\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eudtot5WXDTQ","colab_type":"code","colab":{}},"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","x_train, x_test = x_train.reshape(-1, 28*28)/255.0, x_test.reshape(-1, 28*28)/255.0\n","y_train, y_test = tf.keras.utils.to_categorical(y_train), tf.keras.utils.to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHYmaCE0XKB6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6793249d-0c26-4af9-ce93-abb512228dab","executionInfo":{"status":"ok","timestamp":1588074465835,"user_tz":-540,"elapsed":3260,"user":{"displayName":"JeiKei Lim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBVS8KGCKLy88ikhL2CqJZ1J5awuet90XI1Sgg55E=s64","userId":"06532207265815493900"}}},"source":["y_train.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 10)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"vfv77EHFb2r5","colab_type":"code","colab":{}},"source":["x = np.array([[0,0], [0,1], [1,0], [1,1]])\n","y = np.array([[0], [1], [1], [0]])\n","\n","ann = ANN(layer=[[(784,257), 'relu'], [(256, 129), 'relu'], [(128, 10), 'relu']])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCe-Yz1aN-5K","colab_type":"code","outputId":"43e4aea4-d7e5-46ad-a7de-84cf2807725f","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1588075079545,"user_tz":-540,"elapsed":280641,"user":{"displayName":"JeiKei Lim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBVS8KGCKLy88ikhL2CqJZ1J5awuet90XI1Sgg55E=s64","userId":"06532207265815493900"}}},"source":["ann.fit(x_train,y_train, epoch=10, learning_rate=0.00001, batch_size=100)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch : 01/10 , Loss : 82.147: 100%|██████████| 600/600 [00:27<00:00, 21.54it/s]\n","Epoch : 02/10 , Loss : 79.971: 100%|██████████| 600/600 [00:27<00:00, 21.66it/s]\n","Epoch : 03/10 , Loss : 77.917: 100%|██████████| 600/600 [00:27<00:00, 21.50it/s]\n","Epoch : 04/10 , Loss : 76.572: 100%|██████████| 600/600 [00:28<00:00, 21.35it/s]\n","Epoch : 05/10 , Loss : 75.694: 100%|██████████| 600/600 [00:27<00:00, 21.53it/s]\n","Epoch : 06/10 , Loss : 74.702: 100%|██████████| 600/600 [00:27<00:00, 21.58it/s]\n","Epoch : 07/10 , Loss : 74.275: 100%|██████████| 600/600 [00:28<00:00, 21.20it/s]\n","Epoch : 08/10 , Loss : 73.235: 100%|██████████| 600/600 [00:27<00:00, 21.55it/s]\n","Epoch : 09/10 , Loss : 72.514: 100%|██████████| 600/600 [00:28<00:00, 21.02it/s]\n","Epoch : 10/10 , Loss : 72.214: 100%|██████████| 600/600 [00:28<00:00, 21.39it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["72.21437535627055"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"-xs8e4nDTV2_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"84e027c9-c4fa-414f-f729-54afa0da0731","executionInfo":{"status":"ok","timestamp":1588075083369,"user_tz":-540,"elapsed":677,"user":{"displayName":"JeiKei Lim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBVS8KGCKLy88ikhL2CqJZ1J5awuet90XI1Sgg55E=s64","userId":"06532207265815493900"}}},"source":["np.argmax(ann.forward(x_train[0:10]), axis=1)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 1, 9, 0, 1, 3, 1, 4])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"IfLDxJajg25g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"030cb785-ff8e-4623-a654-fc30c7f61885","executionInfo":{"status":"ok","timestamp":1588075083607,"user_tz":-540,"elapsed":906,"user":{"displayName":"JeiKei Lim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBVS8KGCKLy88ikhL2CqJZ1J5awuet90XI1Sgg55E=s64","userId":"06532207265815493900"}}},"source":["np.argmax(y_train[0:10], axis=1)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"UOFzv8KjlEnV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c571be16-8907-4df8-91e9-48cdb137adf0","executionInfo":{"status":"ok","timestamp":1588075092321,"user_tz":-540,"elapsed":9613,"user":{"displayName":"JeiKei Lim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBVS8KGCKLy88ikhL2CqJZ1J5awuet90XI1Sgg55E=s64","userId":"06532207265815493900"}}},"source":["np.sum(np.argmax(ann.forward(x_train), axis=1) == np.argmax(y_train, axis=1)) / y_train.shape[0]"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5776666666666667"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"33u03V2_g8HN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e90f7ae6-6849-4826-aa10-d2db1cc86085","executionInfo":{"status":"ok","timestamp":1588075093916,"user_tz":-540,"elapsed":11060,"user":{"displayName":"JeiKei Lim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBVS8KGCKLy88ikhL2CqJZ1J5awuet90XI1Sgg55E=s64","userId":"06532207265815493900"}}},"source":["np.sum(np.argmax(ann.forward(x_test), axis=1) == np.argmax(y_test, axis=1)) / y_test.shape[0]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6064"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"RZXVcfzDlC70","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}